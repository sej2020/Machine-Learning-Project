import pandas as pd
import os
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_validate
from sklearn.model_selection import KFold

from sklearn.utils import all_estimators

#Import All Regressions**************************************************************************************************************************

estimators = all_estimators(type_filter='regressor')

all_regs = []
for name, RegressorClass in estimators:
    try:
        if name != 'DummyRegressor' and name != 'GaussianProcessRegressor':
            print('Appending', name)
            reg = RegressorClass()
            all_regs.append(reg)
    except Exception as e:
        print(e)

print(all_regs)

#Load and Describe Data**************************************************************************************************************************
def load_pp_data():
    csv_path = r"C:\Users\18123\OneDrive\Documents\IU Bloomington\Machine-Learning-Project\PowerPlantData\CCPP\Folds5x2_pp.csv"
    return pd.read_csv(csv_path)

pp = load_pp_data()
print(pp.describe())

#Train/Test Split and Prepare Data*************************************************************************************************************
pp["AT_cat"] = pd.cut(pp["AT"],bins=[0.,10.,20.,30.,np.inf],labels=[1,2,3,4])

split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)
for train_index, test_index in split.split(pp,pp["AT_cat"]):
    train_set = pp.loc[train_index]
    test_set = pp.loc[test_index]

for set_ in(train_set,test_set):
    set_.drop("AT_cat",axis=1,inplace=True)

pptrain = train_set.copy()
pptest = test_set.copy()

pptrain_attrib = pptrain.drop("PE",axis=1)
pptrain_labels = pptrain["PE"].copy()
pptest_attrib = pptest.drop("PE",axis=1)
pptest_labels = pptest["PE"].copy()

scaler = StandardScaler()
scaler.fit_transform(pptrain_attrib)

#Simultaneous Run********************************************************************************************************************
def run(model):
    print(f"checking {model}")
    try:
        cv_outer = KFold(n_splits=10, shuffle=True, random_state=2)
        cv_output_dict = cross_validate(model, pptrain_attrib, pptrain_labels, scoring=["neg_mean_squared_error","neg_mean_absolute_error","r2"], cv=cv_outer, return_train_score=True, return_estimator=True)
        return cv_output_dict    
    except:
        pass

def comparison(modellst):
    cv_data = []
    errors = []
    passed_models = []
    for i in range(len(modellst)):
        x = run(modellst[i])
        if type(x) == dict:
            cv_data += [x]
        else:
            errors += [i]
    for j in range(len(modellst)):
        if j not in errors:
            passed_models += [modellst[j]]       
    return vizualize(cv_data, passed_models)

def vizualize(cv_data, modellst):
    return box_mse(cv_data, modellst,'train'), box_mse(cv_data, modellst, 'test'), box_rmse(cv_data, modellst, 'train'), box_rmse(cv_data, modellst, 'test'), box_r2(cv_data, modellst, 'train'), box_r2(cv_data, modellst, 'test'), box_mae(cv_data, modellst, 'train'), box_mae(cv_data, modellst, 'test'), runtime(cv_data, modellst)

def runtime(cv_data, modellst):
    timefig = plt.figure()
    x = []
    for i in cv_data:
        x += [i['fit_time']]
    plt.boxplot(x,vert=False,patch_artist=True,labels=[*modellst])
    xticklst = []
    for j in range(0,10):
        xticklst += [j/1000]    
    plt.xlabel('Run Time')
    return timefig

def box_mse(cv_data, modellst, data_split):
    MSEfig = plt.figure()
    x = []
    for i in cv_data:
        x += [i[data_split+'_neg_mean_squared_error']*-1]
    plt.boxplot(x,vert=False,patch_artist=True,labels=[*modellst])
    plt.xticks([*range(0,45,5)])
    plt.xlabel(f'{data_split} Mean Squared Error (Lower is better)')
    return MSEfig

def box_rmse(cv_data, modellst, data_split):
    RMSEfig = plt.figure()
    x = []
    for i in cv_data:
        x += [np.sqrt(i[data_split+'_neg_mean_squared_error']*-1)]
    plt.boxplot(x,vert=False,patch_artist=True,labels=[*modellst])
    xticklst = []
    for j in range(0,90,5):
        xticklst += [j/10]
    plt.xticks(xticklst)
    plt.xlabel(f'{data_split} Root Mean Squared Error (Lower is better)')
    return RMSEfig

def box_r2(cv_data, modellst, data_split):
    R2fig = plt.figure()
    x = []
    for i in cv_data:
        x += [i[data_split+'_r2']]
    plt.boxplot(x,vert=False,patch_artist=True,labels=[*modellst])
    xticklst = []
    for j in range(70,102,2):
        xticklst += [j/100]
    plt.xticks(xticklst)
    plt.xlabel(f'{data_split} R-Squared Score (Higher is better)')
    return R2fig

def box_mae(cv_data, modellst, data_split):
    MAEfig = plt.figure()
    x = []
    for i in cv_data:
        x += [i[data_split+'_neg_mean_absolute_error']*-1]
    plt.boxplot(x,vert=False,patch_artist=True,labels=[*modellst])
    xticklst = []
    for j in range(0,650,50):
        xticklst += [j/100]
    plt.xticks(xticklst)
    plt.xlabel(f'{data_split} Mean Absolute Error (Lower is better)')
    return MAEfig

y = all_regs[0:20]
x = all_regs[0:3]
comparison(y)
plt.show()