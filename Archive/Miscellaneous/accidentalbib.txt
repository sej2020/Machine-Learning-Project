\bibitem{Katz} J. Katz, \emph{Libraries.io Open Source Repository and Dependency Metadata} (1.6.0), Zenodo, 2020. [Dataset] Available: https://doi.org/10.5281/zenodo.3626071 [Accessed: November 19, 2022]\bibitem{stars} https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars\bibitem{Li} H. Li and C. Bezemer "Studying Popular Open Source Machine Learning Libraries and Their Cross-Ecosystem Bindings" [Online]. Available: arXiv, https://arxiv.org/. [Accessed: November 16, 2022].\bibitem{Katsiapis} K. Katsiapis, “Towards ML engineering: A brief history of tensorflow extended (TFX),” \emph{The TensorFlow Blog}. [Online]. Available: https://blog.tensorflow.org/2020/09/brief-history-of-tensorflow-extended-tfx.html. [Accessed Dec. 17, 2022]. \bibitem{Case} “Case studies,” \emph{TensorFlow}. [Online]. Available: https://www.tensorflow.org/about/case-studies. [Accessed: Dec. 17, 2022].\bibitem{Abadi} M. Abadi et al.,  "TensorFlow: A System for Large-Scale Machine Learning," in  \emph{Proc. of the 12th USENIX Symposium on Operating Systems Design and Implementation OSDI 2016, 2-4 November, 2016, Savannah GA, USA} [Online]. Available: Usenix Association, https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi. [Accessed: Dec 17, 2022].\bibitem{API} “API documentation: tensorflow V2.11.0,” \emph{TensorFlow}. [Online]. Available: https://www.tensorflow.org/api\_docs. [Accessed: Dec. 17, 2022].\bibitem{Aurelien} G. Aur\'{e}lien, \emph{Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build Intelligent Systems}, 2nd ed. Sebastapol, CA: O'Reilly, 2019. \bibitem{Data} “Data preprocessing for ML using TensorFlow transform,” \emph{Google}. [Online]. Available: https://cloud.google.com/architecture/data-preprocessing-for-ml-with-tf-transform-pt2. [Accessed: Dec. 22, 2022]. \bibitem{Guide} “Guide:  TensorFlow Core,” \emph{TensorFlow}. [Online]. Available: https://www.tensorflow.org/guide. [Accessed Dec. 20, 2022].\bibitem{Rumelhart} D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning Representations by Back-Propagating Errors,” \emph{Nature}, vol. 323, no. 6088, pp. 533–536, Oct. 1986. [Online]. Available: https://www.nature.com/articles/323533a0. [Accessed: Dec. 20, 2022].\bibitem{Standardizing} “Standardizing on Keras: Guidance on high-level apis in tensorflow 2.0,” \emph{The TensorFlow Blog}. [Online]. Available: https://blog.tensorflow.org/2018/12/standardizing-on-keras-guidance.html. [Accessed: Dec. 20, 2022]. \bibitem{Keras} Keras, “Keras Documentation: Keras API reference,” \emph{Keras}. [Online]. Available: https://keras.io/api/. [Accessed: Dec. 20, 2022]. \bibitem{Invernizzi} L. Invernizzi, J. Long, F. Chollet, T. O'Malley, and H. Jin, “Keras Documentation: Getting started with Kerastuner,” \emph{Keras}, May 31, 2019. [Online]. Available: https://keras.io/guides/keras\_tuner/getting\_started/\#tune-model-training. [Accessed: Dec. 21, 2022]. \bibitem{Distributed} “Distributed Training with TensorFlow: TensorFlow Core,” \emph{TensorFlow}. [Online]. Available: https://www.tensorflow.org/guide/distributed\_training. [Accessed: Dec. 22, 2022]. \bibitem{TensorBoard} “Get started with TensorBoard,” \emph{TensorFlow}. [Online]. Available: https://www.tensorflow.org/tensorboard/get\_started. [Accessed: Dec. 23, 2022]. \bibitem{scipy} https://projects.scipy.org/scikits.html\bibitem{skabout} https://scikit-learn.org/stable/about.html\bibitem{skgit} https://github.com/scikit-learn/scikit-learn/tree/main/sklearn\bibitem{skuser} https://scikit-learn.org/stable/user\_guide.html\bibitem{dimred} https://www.sciencedirect.com/science/article/pii/S1877050920300879?via\%3Dihub\bibitem{skcluster} https://scikit-learn.org/stable/modules/clustering.html\bibitem{wikireg} https://en.wikipedia.org/wiki/Regression\bibitem{sksup} https://scikit-learn.org/stable/supervised\_learning.html\bibitem{Chen} T. Chen, "MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems," in \emph{Proceedings of Neural Information Processing Systems, Workshop on Machine Learning Systems, 12 December, 2015, Montreal, Canada} [Online]. Available: arXiv, https://arxiv.org/. [Accessed: 5 Jan. 2023].\bibitem{Vogels} W. Vogels, “MXNet - deep learning framework of choice at AWS,” All Things Distributed, 22-Nov-2016. [Online]. Available: https://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html. [Accessed: Jan. 13, 2023].\bibitem{Apache} Apache, “Mxnet/tools/dependencies/README.md,” GitHub. [Online]. Available: https://github.com/apache/mxnet/blob/master/tools/dependencies/README.md. [Accessed: Jan. 13, 2023]. \bibitem{What} “What is MXNet?,” \emph{NVIDIA Data Science Glossary.} [Online]. Available: https://www.nvidia.com/en-us/glossary/data-science/mxnet/. [Accessed: Jan. 13, 2023]. \bibitem{Python} “Python Tutorials,” \emph{Python Tutorials - Apache MXNet documentation}. [Online]. Available: https://mxnet.apache.org/versions/master/api/python/docs/tutorials/. [Accessed: Jan. 7, 2023].\bibitem{Architecture} “MXNet System Architecture,” \emph{Apache MXNet}. [Online]. Available: https://mxnet.apache.org/versions/1.4.1/architecture/overview.html. [Accessed: Jan. 12, 2023]. \bibitem{MXNet} “MXNet - Python API,” \emph{Apache MXNet}. [Online]. Available: https://mxnet.apache.org/versions/1.1.0/api/python/. [Accessed: Jan. 15, 2023]. \bibitem{Gradient} “Gradient Compression,” \emph{Apache MXNet}. [Online]. Available: https://mxnet.apache.org/api/faq/gradient\_compression. [Accessed: Jan. 12, 2023]. \bibitem{PyTorch-neurips}“Pytorch: An imperative style, high-performance deep learning ... - neurips.” [Online]. Available: https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf. [Accessed: 12-Jan-2023].